---
title: "Milestone 2: Core results 01"
author: "Anders"
date: "25/1/2023"
output: pdf_document
#output: html_notebook
editor_options: 
  chunk_output_type: console
---

<!-- ```{r echo=FALSE}  -->
<!-- knitr::opts_chunk$set(echo=FALSE)  -->
<!-- ``` -->

```{r global-options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE)
```

```{r}
library(ggplot2)
```



# Data
One clinical trails on breast cancer (advanced HR+/HER2- and HER2-E breast cancer) using two different drug combination; and a cohorts study (here used as test data set). /
Both data set have 771 genes. This genes are specifically selected based likely potential role in breast cancer. /
The gene set is dived into X numbers of "signature genes"; which are thought to represent unities with respect to cancer biology...

## Trail
Two treatments which differ with respect to drug combination 
- Target: ribociclib and endocrine therapy (letrozole)
- Chemotherapy: doxorubicin, cyclophosphamide and paclitaxel. 
approx. 50 patients in each group.
Endpoints: proliferation score, ROR score

## Cohort
The primary objective of this study is to compare two cdk4/6 targeted drugs (Palbociclib, n=36; Abemaciclib, n=3 in combination with endocrine therapy (tamoxifen, fulvestrant or aromatase inhibitors,  I think?) 

Endpoints: progression free survival (months), OS?, and status of the two former (dont know what that means)

# Major goal
1. Find best model to predict outcome of cancer treatment with genetic profile as predictive features
2. Features selection in order to understand cancer biology

# Major challanges
Preliminary experiments (on trail 1) showed instability in prediction and feature selection between bootstrap samples of Lasso. I believe this is a classical problem of high-dim data?

# Approch
Test all thinkable models to see if some is surperior

# Evaluation of models
Two levels of evaluation is scheduled:

## 1. Relative comparison of models
1000 bootstrap models are fitted and then evaluated on the original sample. This gives a relative comparison of the various models with respect to data similar to the given data set. In addition to Correlation and MSE, frequency of selected features is compared.

## 2. Expected outcome of future patients
3 strategies are considered:  
1. Repeated cross-validations (100 rep) \
2. Bootstrap models with 0.632 (or 0.632?) adjustment \
3. Test data set from a second trail (This trail have different responses) \

# Models
## Lasso
## Post Lasso
## Ridge
## Elastic Net
## Boosting with stumps as base learner
### - mboost
### - xgboost
## Feature selecting ensemble model


# RESULTS

# Lasso

```{r}
report02_out <- function(object){
  cor_vec <- object$correlations
  n_models <- length(cor_vec)
  fr <- sum(is.na(cor_vec))/n_models
  cat("Fraction of model fits with no selected genes:", fr, "\n")
  print("Correlation results:")
  cat("Mean correlation:", mean(na.omit(cor_vec)), "\n") 
  cat("Median correlation:", median(cor_vec, na.rm=TRUE), "\n")
  cat("Variance", var(cor_vec, na.rm=TRUE), "\n")
  print("st.dev.:")
  print(sd(na.omit(lasso_k_ob$correlations)))
  
  # Histogram correlations
  correlations_finite <- cor_vec[is.finite(cor_vec)]
  cor_df <- data.frame(correlation = correlations_finite)
  
  h <- ggplot(cor_df, aes(x=correlation)) +
    geom_histogram(bins = 30, color = "black", fill = "white") +
    xlab("Correlation") +
    ylab("Frequency") +
    ggtitle("Histogram of Correlation Values")
  show(h)
  
  #hist(cor_vec, breaks = 100)
  
  ## MSE
  MSE_vec <- object$MSE_vec
  print(mean(MSE_vec))
  print(sd(MSE_vec))
  # Histogram MSE
  MSE_df <- data.frame(MSE = MSE_vec)
  
  h <- ggplot(MSE_df, aes(x=MSE)) +
    geom_histogram(bins = 30, color = "black", fill = "white") +
    xlab("MSE") +
    ylab("Frequency") +
    ggtitle("Histogram of MSE Values")
  show(h)
  
  ## Most prevalent Features
  # Order the features based on their selection frequency
  coef_matrix <- lasso_k_ob$coef_matrix
  frequency <- data.frame(Feature = colnames(coef_matrix), Frequency = colSums(coef_matrix != 0) / (n_models))
  frequency <- frequency[order(frequency$Frequency, decreasing = TRUE),]
  
  # Bar plot of the selection frequency of the features
  n_best <- 50
  h <- ggplot(frequency[1:n_best ,], aes(x = Frequency, y = reorder(Feature, Frequency))) +
    geom_bar(stat = "identity") +
    xlab("Selection Frequency") +
    ylab("Features") +
    ggtitle("Selection Frequency of Features") +
    theme(axis.text.y = element_text(angle = 0, hjust = 0))
  show(h)
  
  # extract the top features
  perc_best <- 0.9 # how often they where selected in percentage
  top_features_with_index = which(colSums(coef_matrix != 0) >= perc_best * n_models)
  top_feature_names = colnames(coef_matrix)[top_features_with_index]
  print(top_feature_names)
  
  num_features_to_keep <- 10 
  # count the frequency of each feature in coef_matrix
  counts <- colSums(coef_matrix != 0)
  # sort the features based on their frequency
  sorted_features <- names(sort(counts, decreasing = TRUE))
  print(sorted_features[1:num_features_to_keep])
}
```

```{r}
path <- "/Users/anders/Documents/MASTER/Cancer/model_instances/lk_AllGenesProlif.RData"
load(path)
  
report02_out(lasso_k_ob)
```


# Post Lasso
# Ridge
# Elastic Net
# Boosting with stumps as base learner




